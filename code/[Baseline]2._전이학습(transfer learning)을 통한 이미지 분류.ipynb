{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사물이미지 분류 경진대회 베이스라인2 \n",
    "\n",
    "안녕하세요 데이커 여러분! 이전 베이스라인은 잘 보셨나요?\n",
    "\n",
    "이번 베이스라인에서는 딥러닝 모델 구축 시 많이 사용되는 기법인 전이학습(transfer learning) 에 대해 소개하고자 합니다. \n",
    "\n",
    "전이학습이란 이미 구축되어 있는 모델을 사용하는 기법입니다. \n",
    "\n",
    "그럼 본격적으로 코드를 통해 전이학습에 대해 알아보아요! \n",
    "\n",
    "* 코드를 어떻게 실행시켜야 할지 잘 모르시는 분은 아래 \"코랩으로 데이콘 참여하기\"를 먼저 봐주세요!\n",
    "https://dacon.io/competitions/official/235836/talkboard/404882\n",
    "\n",
    "* 데이터를 살펴보는 탐색적 데이터 분석 (Exploratory Data Analysis, EDA) 코드를 먼저 보고 오시면 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 library 들을 load 합니다.\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models import efficientnet_b3 as efficientnet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 load, 전처리\n",
    "\n",
    "데이터를 load 하기 전에 기본적인 전처리 코드를 작성해줍시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #이미지 데이터를 tensor 데이터 포멧으로 바꾸어줍니다.\n",
    "    transforms.Resize([224,224]), #이미지의 크기가 다를 수 있으니 크기를 통일해 줍니다.\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) #픽셀 단위 데이터를 정규화 시켜줍니다.\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 불러와 줍니다. \n",
    "\n",
    "PYTORCH 의 ImageFolder 메소드를 사용하면 folder 의 이름을 자동으로 라벨링이 됩니다.\n",
    "\n",
    "예를 들어 airplane 이라는 folder 내에 이미지 파일들이 있다면, 이미지 파일들의 라벨을 '0' 으로 라벨링이 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root='./data/train/',transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가를 위해 train 데이터에서 validation 데이터를 나누어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(np.arange(len(train_data)), test_size=0.2, \n",
    "                                        random_state=42, shuffle=True, stratify=train_data.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 load 할 batch_size 를 설정해 줍니다. \n",
    "\n",
    "batch_size 란 하드웨어에 한번에 load 할 데이터의 크기입니다. \n",
    "\n",
    "num_workers 란 데이터 로드 멀티 프로세싱을 위한 파라미터입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = int(cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data loader 를 생성해줍니다. \n",
    "\n",
    "data loader 란 데이터 셋을 순회하며 모델에 데이터를 넣어주는 객체입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, \n",
    "                          sampler=SubsetRandomSampler(train_idx), num_workers=num_workers)\n",
    "valid_loader = DataLoader(train_data, batch_size=batch_size, \n",
    "                          sampler=SubsetRandomSampler(valid_idx), num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 크기를 확인해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = len(train_idx)\n",
    "valid_total = len(valid_idx)\n",
    "\n",
    "train_batches = len(train_loader)\n",
    "valid_batches = len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train imgs : 40000 / total train batches : 1250\n",
      "total valid imgs : 10001 / total valid batches : 313\n"
     ]
    }
   ],
   "source": [
    "print('total train imgs :',train_total,'/ total train batches :', train_batches)\n",
    "print('total valid imgs :',valid_total, '/ total valid batches :', valid_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device 설정\n",
    "\n",
    "device 를 설정해줍니다.\n",
    "\n",
    "이번 베이스라인에서는 gpu 가 있다고 가정하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기 / 파라미터 설정\n",
    "\n",
    "전이학습을 위한 모델을 load 해줍니다. \n",
    "\n",
    "PYTORCH 의 models 메소드를 사용하면 손쉽게 외부의 모델을 불러올 수 있습니다.\n",
    "\n",
    "이번 베이스라인에서는 efficientnet_b3 모델을 사용해 볼 것입니다. \n",
    "\n",
    "사전 학습 모델을 사용하는 것은 부정행위에 해당하니, pretrained 파라미터를 False 로 설정해야 합니다!\n",
    "\n",
    "pretrained 파라미터를 True 로 설정한다면, ImageNet 이라는 데이터셋을 대상으로 학습된 모델이 load 됩니다.\n",
    "\n",
    "반면, pretrained 파라미터를 False 로 설정한다면, 모델의 구조만 load 되고 모델의 가중치 들은 load 되지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.3, inplace=True)\n",
       "  (1): Linear(in_features=1536, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.efficientnet_b3(pretrained=False)\n",
    "net.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 데이터를 학습하기 위해서는 모델의 마지막 layer 의 output size 와 분류할 라벨의 수를 입력해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc = nn.Linear(1000, 10)\n",
    "net = net.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 파라미터들을 설정해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 \n",
    "\n",
    "반복문을 이용해 학습을 진행시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.05it/s, Epoch=1, Loss=1.178368]\n",
      "100%|██████████| 313/313 [00:10<00:00, 30.08it/s, Epoch=1, Loss=1.362997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 train loss 1.722855820798874 train acc 0.37455 valid loss 1.3101708439592354 valid acc 0.5107489251074893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.03it/s, Epoch=2, Loss=1.006660]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.77it/s, Epoch=2, Loss=0.990702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 train loss 1.1655808423042298 train acc 0.58715 valid loss 0.9792095011415572 valid acc 0.6475352464753524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s, Epoch=3, Loss=0.884558]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.81it/s, Epoch=3, Loss=0.657171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 train loss 0.9115738003969193 train acc 0.681125 valid loss 0.7767725567848157 valid acc 0.7269273072692731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.01it/s, Epoch=4, Loss=0.626147]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.88it/s, Epoch=4, Loss=0.357846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 train loss 0.7544200906276702 train acc 0.73765 valid loss 0.6904737934136924 valid acc 0.7599240075992401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:19<00:00,  8.99it/s, Epoch=5, Loss=0.652991]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.89it/s, Epoch=5, Loss=0.628644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 train loss 0.6561478651404381 train acc 0.775125 valid loss 0.6094588004171658 valid acc 0.7917208279172083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s, Epoch=6, Loss=0.485479]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.99it/s, Epoch=6, Loss=0.450345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 6 train loss 0.5760294488668442 train acc 0.8003 valid loss 0.5765135013542998 valid acc 0.8056194380561944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.02it/s, Epoch=7, Loss=0.602733]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.69it/s, Epoch=7, Loss=0.238586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 7 train loss 0.5113281104445457 train acc 0.82185 valid loss 0.5927021823847256 valid acc 0.7961203879612039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:19<00:00,  8.99it/s, Epoch=8, Loss=0.530021]\n",
      "100%|██████████| 313/313 [00:10<00:00, 30.24it/s, Epoch=8, Loss=0.326445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 8 train loss 0.4534196371734142 train acc 0.84175 valid loss 0.5423957146109103 valid acc 0.822017798220178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.00it/s, Epoch=9, Loss=0.483433]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.64it/s, Epoch=9, Loss=0.505034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 9 train loss 0.40080086914300916 train acc 0.8616 valid loss 0.5289487347911341 valid acc 0.8208179182081792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:18<00:00,  9.02it/s, Epoch=10, Loss=0.628096]\n",
      "100%|██████████| 313/313 [00:10<00:00, 29.65it/s, Epoch=10, Loss=0.613084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 10 train loss 0.3546241638362408 train acc 0.876975 valid loss 0.5519655163105304 valid acc 0.8181181881811819\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    \n",
    "    train_loss = 0 \n",
    "    train_correct = 0\n",
    "    tqdm_dataset = tqdm(train_loader)\n",
    "    for x,y in tqdm_dataset:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = net(x)\n",
    "        loss = criterion(outputs,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_correct += predicted.eq(y).sum().item()\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(loss.item()),\n",
    "        })\n",
    "\n",
    "    train_loss = train_loss / train_batches\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    net.eval()\n",
    "    \n",
    "    valid_loss = 0 \n",
    "    valid_correct = 0\n",
    "    tqdm_dataset = tqdm(valid_loader)\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm_dataset:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            outputs = net(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            valid_correct += predicted.eq(y).sum().item()\n",
    "            \n",
    "            tqdm_dataset.set_postfix({\n",
    "                'Epoch': epoch + 1,\n",
    "                'Loss': '{:06f}'.format(loss.item()),\n",
    "            })\n",
    "            \n",
    "    valid_loss = valid_loss / valid_batches\n",
    "    valid_acc = valid_correct / valid_total\n",
    "        \n",
    "    print('epochs',epoch+1, 'train loss',train_loss,'train acc', train_acc, 'valid loss',valid_loss, 'valid acc',valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 / 불러오기\n",
    "\n",
    "학습된 모델의 가중치를 저장합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './model.pth'\n",
    "torch.save(net.state_dict(),path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './model.pth'\n",
    "net.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 \n",
    "\n",
    "이제 학습이 완료되었습니다! \n",
    "\n",
    "그럼 test 데이터를 예측해 보아요.\n",
    "\n",
    "test 데이터를 불어옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "test_images = []\n",
    "\n",
    "path = './data/'\n",
    "for filename in sorted(glob(path + \"test/*.jpg\")):\n",
    "    an_img = PIL.Image.open(filename) \n",
    "    img_array = np.array(an_img) \n",
    "    test_images.append(img_array) \n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform \n",
    "        self.img_list = test_images\n",
    "        self.img_labels = [0] * 10000 \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.img_list[idx]), self.img_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CustomDataset(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_set, batch_size = batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본격적으로 test 데이터를 예측해보아요! \n",
    "\n",
    "예측을 할 때는 학습이 진행되지 않도록 net.eval() 코드를 작성해주어야 합니다. \n",
    "\n",
    "데이터가 backpropagation 되어 가중치가 수정되지 않도록 해주는 코드입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "net.eval()\n",
    "\n",
    "batch_index = 0\n",
    "\n",
    "for i, (images, targets) in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    outputs = net(images)\n",
    "    batch_index = i * batch_size\n",
    "    max_vals, max_indices = torch.max(outputs, 1)\n",
    "    sample_submission.iloc[batch_index:batch_index + batch_size, 1:] = max_indices.long().cpu().numpy()[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측된 데이터의 라벨은 숫자로 되어있습니다. \n",
    "\n",
    "train 데이터를 불러올 때 ImageFolder 메소드를 사용해 데이터를 불러왔기 때문입니다. \n",
    "\n",
    "제출을 위해 라벨을 다시 복원 시켜 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
    "          5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "sample_submission['target'] = sample_submission['target'].map(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.jpg</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.jpg</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    target\n",
       "0  0000.jpg     horse\n",
       "1  0001.jpg  airplane\n",
       "2  0002.jpg  airplane\n",
       "3  0003.jpg      bird\n",
       "4  0004.jpg  airplane"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "축하합니다! 데이터 분석을 완료하셨습니다!\n",
    "\n",
    "앞으로도 데이콘과 함께 즐겁게 데이터 분석 능력을 키워가시면 좋겠습니다.\n",
    "\n",
    "감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subin",
   "language": "python",
   "name": "subin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
